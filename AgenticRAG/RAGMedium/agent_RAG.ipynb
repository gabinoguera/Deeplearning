{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agentic RAG from: https://medium.com/the-ai-forum/multi-document-agentic-rag-using-llama-index-and-mistral-b334fa45d3ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader,VectorStoreIndex,SummaryIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.tools import FunctionTool,QueryEngineTool\n",
    "from llama_index.core.vector_stores import MetadataFilters,FilterCondition\n",
    "from typing import List,Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Document Metadata: {'page_label': '1', 'file_name': 'Utel_Espana_Fichas_Tecnicas_Grado_Ingenieria_Industrial_e5cfa85380.pdf', 'file_path': 'data\\\\Utel_Espana_Fichas_Tecnicas_Grado_Ingenieria_Industrial_e5cfa85380.pdf', 'file_type': 'application/pdf', 'file_size': 372978, 'creation_date': '2024-07-04', 'last_modified_date': '2024-06-18'}\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(input_files = ['./data/Utel_Espana_Fichas_Tecnicas_Grado_Ingenieria_Industrial_e5cfa85380.pdf']).load_data()\n",
    "print(len(documents))\n",
    "print(f\"Document Metadata: {documents[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of nodes : 3\n",
      "get the content for node 0 :page_label: 1\n",
      "file_name: Utel_Espana_Fichas_Tecnicas_Grado_Ingenieria_Industrial_e5cfa85380.pdf\n",
      "file_path: data\\Utel_Espana_Fichas_Tecnicas_Grado_Ingenieria_Industrial_e5cfa85380.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 372978\n",
      "creation_date: 2024-07-04\n",
      "last_modified_date: 2024-06-18\n",
      "\n",
      "Grado en\n",
      "Ingeniería Industrial\n",
      "Sobre el grado\n",
      "Con este grado, tu potencial te llevará a diseñar \n",
      "todos los procesos de una empresa, inﬂuir en todas sus áreas y sacar lo mejor de cada colaborador y colaboradora utilizando síntesis de la ingeniería y el diseño para evaluar y mejorar los resultados. Esta ingeniería busca instruirte en el equipamiento, energía, materiales y procesos de producción de alta calidad y servicios útiles con alta consideración al medio ambiente.\n",
      "Dónde podrás trabajar\n",
      "Con\n",
      "trol de calidad\n",
      "Asegura el cumplimiento de todas las características y herramientas de productos y servicios.\n",
      "Procesos y manufactura\n",
      "Mejora los procesos y propón estrategias sustentables de crecimiento.\n",
      "Producción\n",
      "Implementa estrategias de optimización para conseguir el rendimiento máximo de procesos industriales.\n",
      "Logística\n",
      "Demuestra tu capacidad de análisis, interpretación, comprensión, diseño, programación y control de sistemas productivos y logísticos.Lo que aprenderás\n",
      "Planes estratégicos de negociosDiseña e implementa planes estratégicos de negocios y sistemas para adaptar nuevas tecnologías, reducir desperdicios, mejorar las condiciones de trabajo y los estándares de productividad desde una perspectiva de mejores prácticas directivas y de management.\n",
      "Alineación de los procesos de negocio\n",
      "Fomenta la productividad de las empresas alineando todos sus procesos a lo largo de la cadena de suministro analizando, diseñando, implementando y manteniendo sistemas que mejorarán su eﬁciencia para balancear la producción y optimizar sus procesos.\n",
      "Desarrollo de sistemas de control\n",
      "Lidera sistemas de control para lograr objetivos determinados regulando la forma en que se comporta otro sistema para así evitar fallas. Con estos controles podrás brindar apoyo a la planeación ﬁnanciera, análisis de costos y diseñar sistemas productivos y cadenas de suministros.\n",
      "Gestión de procesos\n",
      "Aprovecha al máximo los recursos para que no haya desperdicios o mermas, reduciendo los tiempos de producción de operadores y maquinarias para aprovechar cada segundo y así maximizar las ganancias de la empresa.\n",
      "utel.edu.mx/espana\n"
     ]
    }
   ],
   "source": [
    "splitter = SentenceSplitter(chunk_size=1024,chunk_overlap=100)\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "print(f\"Length of nodes : {len(nodes)}\")\n",
    "print(f\"get the content for node 0 :{nodes[0].get_content(metadata_mode='all')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db_mistral\")\n",
    "chroma_collection = db.get_or_create_collection(\"multidocument-agent\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77492b4cadd0478cb2283fb1b75887b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff883514aa83402cbfdeac2711a0ed5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d815d8f20dd64178abb5715a9bd8d94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabriel.hernan\\Desktop\\papeles personales\\Deeplearning\\AgenticRAG\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\gabriel.hernan\\AppData\\Local\\Temp\\fastembed_cache\\models--qdrant--bge-small-en-v1.5-onnx-q. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5c7b8d52a44a9f93fc1aa7d0ba6c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7fa18de9094d1283e1fd1f0ab80738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_optimized.onnx:   0%|          | 0.00/66.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0722eb0ac0477bb3456eef219cc491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/706 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "from llama_index.core import Settings\n",
    "#\n",
    "embed_model = FastEmbedEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "#\n",
    "Settings.embed_model = embed_model\n",
    "#\n",
    "Settings.chunk_size = 1024\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.mistralai import MistralAI\n",
    "from helper import get_mistral_api_key\n",
    "MISTRAL_API_KEY = get_mistral_api_key()\n",
    "llm = MistralAI(model=\"mistral-large-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the Vector Query tool and summary tool for specific document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate Vectorstore\n",
    "name = \"BERT_arxiv\"\n",
    "vector_index = VectorStoreIndex(nodes,storage_context=storage_context)\n",
    "vector_index.storage_context.vector_store.persist(persist_path=\"/content/chroma_db\")\n",
    "#\n",
    "# Define Vectorstore Autoretrieval tool\n",
    "def vector_query(query:str,page_numbers:Optional[List[str]]=None)->str:\n",
    "  '''\n",
    "  perform vector search over index on\n",
    "  query(str): query string needs to be embedded\n",
    "  page_numbers(List[str]): list of page numbers to be retrieved,\n",
    "                          leave blank if we want to perform a vector search over all pages\n",
    "  '''\n",
    "  page_numbers = page_numbers or []\n",
    "  metadata_dict = [{\"key\":'page_label',\"value\":p} for p in page_numbers]\n",
    "  #\n",
    "  query_engine = vector_index.as_query_engine(similarity_top_k =2,\n",
    "                                              filters = MetadataFilters.from_dicts(metadata_dict,\n",
    "                                                                                    condition=FilterCondition.OR)\n",
    "                                              )\n",
    "  #\n",
    "  response = query_engine.query(query)\n",
    "  return response\n",
    "#\n",
    "#llamiondex FunctionTool wraps any python function we feed it\n",
    "vector_query_tool = FunctionTool.from_defaults(name=f\"vector_tool_{name}\",\n",
    "                                              fn=vector_query)\n",
    "# Prepare Summary Tool\n",
    "summary_index = SummaryIndex(nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(response_mode=\"tree_summarize\",\n",
    "                                                      se_async=True,)\n",
    "summary_query_tool = QueryEngineTool.from_defaults(name=f\"summary_tool_{name}\",\n",
    "                                                    query_engine=summary_query_engine,\n",
    "                                                  description=(\"Use ONLY IF you want to get a holistic summary of the documents.\"\n",
    "                                              \"DO NOT USE if you have specified questions over the documents.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: vector_tool_BERT_arxiv with args: {\"query\": \"summarize the content\", \"page_numbers\": [\"2\"]}\n",
      "=== Function Output ===\n",
      "The academic validity of the Industrial Engineering degree program at Utel is recognized by the Mexican National Education System. The program offers concentrations in Administration, Information Technologies, and Finance. It consists of 300 credits covering subjects such as industry structure, algebra, sustainable development, physics, statistics, and more. Students choose two professional paths within their concentration area and complete four co-curricular subjects. The program duration is typically four years internationally, with the option for a more accelerated pace. Additionally, students must take three Advanced Workshops focusing on Employability, Social Impact, and Digital Skills to enhance the quality of their education.\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call([vector_query_tool],\n",
    "                                \"Summarize the content in page number 2\",\n",
    "                                verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to generate Vectorstore Tool and Summary tool for all the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_tools(file_path:str,name:str)->str:\n",
    "  '''\n",
    "  get vector query and sumnmary query tools from a document\n",
    "  '''\n",
    "  #load documents\n",
    "  documents = SimpleDirectoryReader(input_files = [file_path]).load_data()\n",
    "  print(f\"length of nodes\")\n",
    "  splitter = SentenceSplitter(chunk_size=1024,chunk_overlap=100)\n",
    "  nodes = splitter.get_nodes_from_documents(documents)\n",
    "  print(f\"Length of nodes : {len(nodes)}\")\n",
    "  #instantiate Vectorstore\n",
    "  vector_index = VectorStoreIndex(nodes,storage_context=storage_context)\n",
    "  vector_index.storage_context.vector_store.persist(persist_path=\"/content/chroma_db\")\n",
    "  #\n",
    "  # Define Vectorstore Autoretrieval tool\n",
    "  def vector_query(query:str,page_numbers:Optional[List[str]]=None)->str:\n",
    "    '''\n",
    "    perform vector search over index on\n",
    "    query(str): query string needs to be embedded\n",
    "    page_numbers(List[str]): list of page numbers to be retrieved,\n",
    "                            leave blank if we want to perform a vector search over all pages\n",
    "    '''\n",
    "    page_numbers = page_numbers or []\n",
    "    metadata_dict = [{\"key\":'page_label',\"value\":p} for p in page_numbers]\n",
    "    #\n",
    "    query_engine = vector_index.as_query_engine(similarity_top_k =2,\n",
    "                                                filters = MetadataFilters.from_dicts(metadata_dict,\n",
    "                                                                                     condition=FilterCondition.OR)\n",
    "                                                )\n",
    "    #\n",
    "    response = query_engine.query(query)\n",
    "    return response\n",
    "  #\n",
    "  #llamiondex FunctionTool wraps any python function we feed it\n",
    "  vector_query_tool = FunctionTool.from_defaults(name=f\"vector_tool_{name}\",\n",
    "                                                fn=vector_query)\n",
    "  # Prepare Summary Tool\n",
    "  summary_index = SummaryIndex(nodes)\n",
    "  summary_query_engine = summary_index.as_query_engine(response_mode=\"tree_summarize\",\n",
    "                                                       se_async=True,)\n",
    "  summary_query_tool = QueryEngineTool.from_defaults(name=f\"summary_tool_{name}\",\n",
    "                                                     query_engine=summary_query_engine,\n",
    "                                                    description=(\"Use ONLY IF you want to get a holistic summary of the documents.\"\n",
    "                                                \"DO NOT USE if you have specified questions over the documents.\"))\n",
    "  return vector_query_tool,summary_query_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a input list with specified document names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_path = \"/content/data\"\n",
    "file_name = []\n",
    "file_path = []\n",
    "for files in os.listdir(root_path):\n",
    "  if file.endswith(\".pdf\"):\n",
    "    file_name.append(files.split(\".\")[0])\n",
    "    file_path.append(os.path.join(root_path,file))\n",
    "#\n",
    "print(file_name)\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the vectortool and summary tool for each documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_to_tools_dict = {}\n",
    "for name,filename in zip(file_name,file_path):\n",
    "  vector_query_tool,summary_query_tool = get_doc_tools(filename,name)\n",
    "  papers_to_tools_dict[name] = [vector_query_tool,summary_query_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the tools into a flat list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tools = [t for f in file_name for t in papers_to_tools_dict[f]]\n",
    "initial_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "#\n",
    "obj_index = ObjectIndex.from_objects(initial_tools,index_cls=VectorStoreIndex)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the ObjectIndex as retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_retriever = obj_index.as_retriever(similarity_top_k=2)\n",
    "tools = obj_retriever.retrieve(\"compare and contrast the papers self rag and corrective rag\")\n",
    "#\n",
    "print(tools[0].metadata)\n",
    "print(tools[1].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the RAG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "#\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(tool_retriever=obj_retriever,\n",
    "                                                     llm=llm,\n",
    "                                                     system_prompt=\"\"\"You are an agent designed to answer queries over a set of given papers.\n",
    "                                                     Please always use the tools provided to answer a question.Do not rely on prior knowledge.\"\"\",\n",
    "                                                     verbose=True)\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "response = agent.query(\"Compare and contrast self rag and crag.\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.query(\"Summarize the paper corrective RAG.\")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
